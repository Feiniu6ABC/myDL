

    1.DNN 可设置网络结构参数，层数，神经元个数，激活函数

--------------------------------------------------------

    2.初始化： Random，"he"，"arXiv"
    
    3.方差/偏差： Regularization， Dropout
    
    4 随机采样： Stochastic gradient descent，mini-batch
    
    5 优化方法： Gradient Descent，Momentum Gradient Descent，Adam
    
    6 矩阵库更新： 主要考虑内存分配问题，但存在申请内存失败问题
    
--------------------------------------------------------------------
    1 深度神经网络: C++/python/TF 实现
    
    2 卷积神经网络: python/TF 实现
    
    3 序列模型: python/TF 实现 (RNN GRU LSTM)  
    
    4 DeepLearing学习笔记：
提纲
1神经网络构建
	1.1神经网络基础
		逻辑回归模型，Softmax，矩阵形式表示
	1.2 神经网络的前向传递和反向传播的数学推导
		线性，激活函数，损失函数，需要注意的是数据表示，维度问题
2 改善神经网络
	2.1 防止过拟合  提前结束， 增加训练样本， 正则项， Dropout
	2.2 梯度消失问题  初始化，梯度剪辑，激活函数, Bitch-Norm，Res-net，LSTM
	2.3 优化方法（加速 学习率）  Mini-batch，动量的梯度下降，RMS-prop，Adam
	2.4 梯度检验， 调参（网络结构：层，神经元个数；学习率： ；优化方法： ；正则化项： ；Dropout；Mini-batch size；迭代次数；初始化方式）
3 结构化机器学习
	3.1 快速搭建好第一个系统：框架使用，开源使用， 迁移学习，数据预处理
	3.2 误差分析：偏差和方差分析，正交化调试，控制变量法调试	
		1 偏差问题，调整网络架构，学习率，优化方法，增加数据集
        	2 方差问题（过拟合），正则化，Dropout，增加训练集
        	3 真实数据场景差 真实数据与训练测试数据分布不一致
    	3.3 单一评价标准，如F1值结合了精度和召回率
4 卷积神经网络
	4.1 卷积，池化，填充，全连接概念以及超参数和参数（参数共享，特征提取思想）
	4.2 CNN构建的流程以及数学表示形式，需要注意的是，数据表示，维度问题
        	1 卷积，Relu，池化，向量化，全连接，Softmax层，前向传播
        	2 卷积，池化，全连接，Softmax层，链式求导
	4.3 经典的CNN架构
		LeNet-5，AlexNet，VGG（卷积核大小统一化），Resnet（解决梯度消失问题），Inception（可学习卷积核大小），迁移学习构建初始网络架构
5 序列模型
	5.1 序列模型架构：many-to-many（实体识别，机器翻译）， many-to-one（情感分类），one-to-many（语音生成），one-to-one
	5.2 网络架构：RNN，GRU，LSTM，B-RNN，D-RNN 前向反向数学推导，需要注意的是数据表示，维度问题
	5.3 Embeding：上下文关系学习词向量（*），skipgram，负采用，Glove词向量，去偏见，注意力机制（上下文加权）
    
 

    
    

    
